{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "# ECE449 Machine Learning - Assignment 2\n",
    "\n",
    "## Task 3: LeNet with PyTorch\n",
    "\n",
    "\n",
    "[//]: # \"Notebook Created by Jinghua Wang (jinghuawang@intl.zju.edu.cn), last modified on 2020-11-04\"\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "*LeNet* is one of the first published CNNs to capture wide attention for its performance on computer vision image classification tasks.\n",
    "The model was introduced by (and named for) Yann LeCun, then a researcher at AT&T Bell Labs, for the purpose of recognizing handwritten digits in images, in the paper \"Gradient-Based Learning Applied to Document Recognition\" by Yann LeCun, Leon Boottou, Yoshua Bengio, and Patrick Haffner.\n",
    "The paper is available online at: http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf.\n",
    "\n",
    "\n",
    "## LeNet\n",
    "\n",
    "At a high level, LeNet (LeNet-5) consists of two parts:\n",
    "\n",
    "(i) A convolutional encoder consisting of two convolutional layers.\n",
    "\n",
    "(ii) A dense block consisting of three fully-connected layers.\n",
    "\n",
    "Below is the data flow in LeNet, the input is a handwritten digit, the output a probability over 10 possible outcomes:\n",
    "<img src=\"img/lenet.png\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "We took a small liberty with the original LeNet-5 model by removing the Gaussian activation in the final layer.\n",
    "Other than that, our LeNet architechture should match the original LeNet-5 architecture.\n",
    "\n",
    "Below is our LeNet architechture with more structural details. You may check this figure below carefully before you start your LeNet implementation.\n",
    "\n",
    "<img src=\"img/lenet-vert.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "From the structual perspective, note that the height and width of the output of each layer throughout the convolutional block are reduced (compared with the previous layer):\n",
    "\n",
    "The first convolutional layer uses 2 pixels of padding to compensate for the reduction in height and width that would otherwise result from using a $5 \\times 5$ kernel.\n",
    "\n",
    "The second convolutional layer forgoes padding, and thus the height and width are both reduced by 4 pixels. \n",
    "\n",
    "As we go up the stack of layers, the number of channels increases layer-over-layer from 1 in the input to 6 after the first convolutional layer and 16 after the second convolutional layer.\n",
    "\n",
    "Meanwhile, each pooling layer halves the height and width.\n",
    "\n",
    "Finally, each fully-connected layer reduces dimensionality, emitting an output whose dimension matches the total number of classes in our classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build LeNet and train this CNN using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "### We provide you this file so that you can test and debug your task 3 implementations in your .py file by yourself, you don't need to modify any code in this jupyter notebook, but you are welcome to change implementations in this notebook if you want to play with this example model training process.\n",
    "    \n",
    "### You don't need to submit this notebook.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use automatic reloading for your code from task3-template.py\n",
    "# remember to rename task3-template.py before you submit it.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from task3_template import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load your LeNet-5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_lenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 6,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The output data shapes of all layers in your lenet are:\nReshape output shape: \t torch.Size([1, 1, 28, 28])\nConv2d output shape: \t torch.Size([1, 6, 28, 28])\nSigmoid output shape: \t torch.Size([1, 6, 28, 28])\nAvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\nConv2d output shape: \t torch.Size([1, 16, 10, 10])\nSigmoid output shape: \t torch.Size([1, 16, 10, 10])\nAvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\nFlatten output shape: \t torch.Size([1, 400])\nLinear output shape: \t torch.Size([1, 120])\nSigmoid output shape: \t torch.Size([1, 120])\nLinear output shape: \t torch.Size([1, 84])\nSigmoid output shape: \t torch.Size([1, 84])\nLinear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "print(\"The output data shapes of all layers in your lenet are:\")\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The output data shapes of all layers in correct lenet are:\nReshape output shape: \t torch.Size([1, 1, 28, 28])\nConv2d output shape: \t torch.Size([1, 6, 28, 28])\nSigmoid output shape: \t torch.Size([1, 6, 28, 28])\nAvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\nConv2d output shape: \t torch.Size([1, 16, 10, 10])\nSigmoid output shape: \t torch.Size([1, 16, 10, 10])\nAvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\nFlatten output shape: \t torch.Size([1, 400])\nLinear output shape: \t torch.Size([1, 120])\nSigmoid output shape: \t torch.Size([1, 120])\nLinear output shape: \t torch.Size([1, 84])\nSigmoid output shape: \t torch.Size([1, 84])\nLinear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"The output data shapes of all layers in correct lenet are:\")\n",
    "print(get_correct_lenet_shape_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the two cells above, all the layer names, and the output data shapes of all the layers should be the same. \n",
    "#### (Please do not modify the layer names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "###  2. Train your LeNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 11332, 17452) exited unexpectedly",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mD:\\Programs\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\miniconda3\\envs\\torch\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-756b878ea82d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 11332, 17452) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for X, y in train_iter:\n",
    "    print(len(X))\n",
    "    print(len(y))\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "Now let us train and evaluate the LeNet-5 model using your implementation.\n",
    "\n",
    "We recommend using Deep Learning accleration hardware (like CUDA compatible GPU). However, if you are using Mac or other computer without CUDA GPU, it is okay. After all, you only need to run LeNet training for 10 epochs.\n",
    "\n",
    "If you are running without Deep Learning accleration hardware, we recommend that you print out test batch accuracy for every batch in every epoch in the training process, which might make things easier for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "origin_pos": 19,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | batch: 0 | cost: 2.31219482421875\n",
      "epoch: 0 | batch: 50 | cost: 2.3105642795562744\n",
      "epoch: 0 | batch: 100 | cost: 2.311424493789673\n",
      "epoch: 0 | batch: 150 | cost: 2.294754981994629\n",
      "epoch: 0 | batch: 200 | cost: 2.2430548667907715\n",
      "epoch: 1 | batch: 0 | cost: 1.653808355331421\n",
      "epoch: 1 | batch: 50 | cost: 1.1637475490570068\n",
      "epoch: 1 | batch: 100 | cost: 1.0297045707702637\n",
      "epoch: 1 | batch: 150 | cost: 0.8948513269424438\n",
      "epoch: 1 | batch: 200 | cost: 0.9997429251670837\n",
      "epoch: 2 | batch: 0 | cost: 0.7822579145431519\n",
      "epoch: 2 | batch: 50 | cost: 0.9637014269828796\n",
      "epoch: 2 | batch: 100 | cost: 0.7609109878540039\n",
      "epoch: 2 | batch: 150 | cost: 0.633844256401062\n",
      "epoch: 2 | batch: 200 | cost: 0.8041054606437683\n",
      "epoch: 3 | batch: 0 | cost: 0.6174492835998535\n",
      "epoch: 3 | batch: 50 | cost: 0.7399461269378662\n",
      "epoch: 3 | batch: 100 | cost: 0.6168337464332581\n",
      "epoch: 3 | batch: 150 | cost: 0.5519801378250122\n",
      "epoch: 3 | batch: 200 | cost: 0.5882014036178589\n",
      "epoch: 4 | batch: 0 | cost: 0.7036569118499756\n",
      "epoch: 4 | batch: 50 | cost: 0.7203984260559082\n",
      "epoch: 4 | batch: 100 | cost: 0.451332151889801\n",
      "epoch: 4 | batch: 150 | cost: 0.5100128054618835\n",
      "epoch: 4 | batch: 200 | cost: 0.5567277669906616\n",
      "epoch: 5 | batch: 0 | cost: 0.6059768795967102\n",
      "epoch: 5 | batch: 50 | cost: 0.5315588116645813\n",
      "epoch: 5 | batch: 100 | cost: 0.4733818769454956\n",
      "epoch: 5 | batch: 150 | cost: 0.5533576607704163\n",
      "epoch: 5 | batch: 200 | cost: 0.5365884304046631\n",
      "epoch: 6 | batch: 0 | cost: 0.6129502058029175\n",
      "epoch: 6 | batch: 50 | cost: 0.46772998571395874\n",
      "epoch: 6 | batch: 100 | cost: 0.5849113464355469\n",
      "epoch: 6 | batch: 150 | cost: 0.4457976520061493\n",
      "epoch: 6 | batch: 200 | cost: 0.5030519962310791\n",
      "epoch: 7 | batch: 0 | cost: 0.5969828963279724\n",
      "epoch: 7 | batch: 50 | cost: 0.4897395372390747\n",
      "epoch: 7 | batch: 100 | cost: 0.3747527599334717\n",
      "epoch: 7 | batch: 150 | cost: 0.43021082878112793\n",
      "epoch: 7 | batch: 200 | cost: 0.45585089921951294\n",
      "epoch: 8 | batch: 0 | cost: 0.4959728717803955\n",
      "epoch: 8 | batch: 50 | cost: 0.4376281499862671\n",
      "epoch: 8 | batch: 100 | cost: 0.45639973878860474\n",
      "epoch: 8 | batch: 150 | cost: 0.3805573582649231\n",
      "epoch: 8 | batch: 200 | cost: 0.3942866623401642\n",
      "epoch: 9 | batch: 0 | cost: 0.5548728108406067\n",
      "epoch: 9 | batch: 50 | cost: 0.42766883969306946\n",
      "epoch: 9 | batch: 100 | cost: 0.4762585461139679\n",
      "epoch: 9 | batch: 150 | cost: 0.4060617983341217\n",
      "epoch: 9 | batch: 200 | cost: 0.44874247908592224\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 1.1, 10\n",
    "# We recommend not to start training before you have got the correct LeNet-5 model\n",
    "train_cnn(net, train_iter, test_iter, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "After model training, your LeNet-5 achieves test dataset accuracy: 0.8111\n"
     ]
    }
   ],
   "source": [
    "test_dataset_accuracy = evaluate_accuracy_try_gpu(net, test_iter)\n",
    "print(\"After model training, your LeNet-5 achieves test dataset accuracy:\",test_dataset_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After 10 epochs of training with learning rate 0.9~1.1, batch size 256, a test dataset accuracy(on all 10000 test samples) >0.7000 is usually considered correct and will give you a full score for train_cnn function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing task 3!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python379jvsc74a57bd0ff3b8625e759547c540aa11bd3cd73160d87387f6a012c25f097ed27e314a213",
   "display_name": "Python 3.7.9 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}